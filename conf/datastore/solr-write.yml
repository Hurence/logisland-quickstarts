#########################################################################################################
# Logisland configuration script tempate
#########################################################################################################

version: 1.1.2
documentation: LogIsland analytics main config file. Put here every engine or component config

#########################################################################################################
# engine
engine:
  component: com.hurence.logisland.engine.spark.KafkaStreamProcessingEngine
  type: engine
  documentation: Index some apache logs with logisland
  configuration:
    spark.app.name: SolrWriteLogs
    spark.master: local[4]
    spark.driver.memory: 2G
    spark.streaming.batchDuration: 200
    spark.streaming.kafka.maxRatePerPartition: 3000
    spark.streaming.timeout: -1
    spark.ui.port: 4050

  controllerServiceConfigurations:

    - controllerService: datastore_service
      component: com.hurence.logisland.service.solr.Solr_8_ClientService
      type: service
      documentation: "SolR 6.6.2 service"
      configuration:
        solr.cloud: false
        solr.connection.string: ${SOLR_CONNECTION}
        solr.collection: solr-apache-logs
        solr.concurrent.requests: 4
        flush.interval: 2000
        batch.size: 1000

  streamConfigurations:

    # main processing stream
    - stream: parsing_stream
      component: com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing
      type: stream
      documentation: a processor that converts raw apache logs into structured log records
      configuration:
        kafka.input.topics: logisland_raw
        kafka.output.topics: logisland_events
        kafka.error.topics: logisland_errors
        kafka.input.topics.serializer: none
        kafka.output.topics.serializer: com.hurence.logisland.serializer.KryoSerializer
        kafka.error.topics.serializer: com.hurence.logisland.serializer.JsonSerializer
        kafka.metadata.broker.list: ${KAFKA_BROKERS}
        kafka.zookeeper.quorum: ${ZK_QUORUM}
        kafka.topic.autoCreate: true
        kafka.topic.default.partitions: 4
        kafka.topic.default.replicationFactor: 1
      processorConfigurations:

        # parse apache logs into logisland records
        - processor: apache_parser
          component: com.hurence.logisland.processor.SplitText
          type: parser
          documentation: a parser that produce events from an apache log REGEX
          configuration:
            record.type: apache_log
            value.regex: (\S+)\s+(\S+)\s+(\S+)\s+\[([\w:\/]+\s[+\-]\d{4})\]\s+"(\S+)\s+(\S+)\s*(\S*)"\s+(\S+)\s+(\S+)
            value.fields: src_ip,identd,user,record_time,http_method,http_query,http_version,http_status,bytes_out

        # all the parsed records are added to solr by bulk
        - processor: solr_publisher
          component: com.hurence.logisland.processor.datastore.BulkPut
          type: processor
          documentation: "indexes processed events in SolR"
          configuration:
            datastore.client.service: datastore_service
